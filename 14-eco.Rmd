# Geocomputation for Ecology: A case study of fog oases {#eco}

## Prerequisites {-}

This chapter assumes you have a strong grasp of spatial data analysis and processing, covered in chapters 2-5.
In it you will make use of R's interfaces to dedicated GIS software, and spatial cross validation, topics covered in chapters \@ref(gis) and \@ref(spatial-cv) respectively.

The chapter uses the following packages:

```{r, message=FALSE} 
library(sf)
library(raster)
library(RQGIS)
library(mlr)
library(parallelMap)
library(dplyr)
```

## Introduction

keywords: species distribution modeling, floristic modeling, spatial cross-validation, spatial autocorrelation, ordination (NMDS, Isomap), predictive mapping

structure:

1. intro ecological modeling and related applications beyond ecology
2. introduce research question, shortly the dataset and the planned approach
3. ordination
4. retrieving predictors and quick data exploration
5. modeling ordination scores most likely using machine-learning since we are mostly interested in spatial predictions, and because the mlr spatial cv approach is new, and finally because Alain Zuur's books cover statistical inference broadly
6. predictive mapping of floristic composition including spatial cross-validation
7. discussion: what could be done better or alternatives and again emphasizing that the methods shown
finally, point to books on ecological modeling especially emphasizing Alain Zuur's books


## Background

Fog oases are one of the most fascinating vegetation formations I have ever encountered. 
These formations, locally termed *lomas*, develop on mountains along the coastal deserts of Peru and Chile.
The deserts' extreme conditions and remoteness provide the habitat for a unique ecosystem, including species endemic to the fog oases.
Despite the arid conditions and low levels of precipitation of around 30-50 mm per year on average, plants can survive, by 'combing out' fog.
This fog, which develops below the temperature inversion caused by the cold Humboldt current in austral winter, provides the name for this habitat.
Every few years, the El Niño phenomenon brings torrential rainfall to this sun-baked environment [@dillon_lomas_2003].
This causes the desert to bloom, and provides tree seedlings a chance to develop roots long enough to survive the following arid conditions.

Unfortunately fog oases are heavily endangered.
This is mostly due to human activity (agriculture and climate change).
To effectively protect the last remnants of this unique vegetation ecosystem, evidence is needed on the composition and spatial distribution of the native flora [@muenchow_predictive_2013; @muenchow_soil_2013].
*Lomas* mountains also have economic value as a tourist destination, and can contribute to the wellbeing of local people via recreation.
For example, most Peruvians live in the coastal desert, and *lomas* mountains are frequently the closest "green" destination.

In this chapter we will demonstrate ecological applications of some of the techniques learned in the previous chapters.
This case study will involve analyzing the composition and the spatial distribution of the vascular plants on the southern slope of Mt. Mongón, a *lomas* mountain near Casma on the central northern coast of Peru (Fig. \@ref(fig:study-area-mongon)).

```{r study-area-mongon, echo = FALSE, fig.cap = "The Mt. Mongón study area (taken from @muenchow_rqgis:_2017; Landsat image: path 9, row 67, acquisition date 09/22/2000; @usgs_u.s._2016)."}
knitr::include_graphics("https://user-images.githubusercontent.com/1825120/38989956-6eae7c9a-43d0-11e8-8f25-3dd3594f7e74.png")
```

During a field study to Mt. Mongón we recorded all vascular plants living in 100 randomly sampled 4x4 m^2^ plots in the austral winter of 2011 [@muenchow_predictive_2013].
The sampling coincided with a strong La Niña event that year (see ENSO monitoring of the [NOASS Climate Prediction Center](http://origin.cpc.ncep.noaa.gov/products/analysis_monitoring/ensostuff/ONI_v5.php)).
This led to even higher levels of aridity than usual in the coastal desert.
By contrast, it increased fog activity on the southern slopes of Peruvian *lomas* mountains.

<!--
The first hypothesis is that four plant belts will be found along the altitudinal gradient: a low-elevation *Tillandsia* belt, a herbaceous belt, a bromeliad belt, and an uppermost succulent belt [@muenchow_soil_2013].
-->

Ordinations are dimension-reducing techniques which allow the extraction of the main gradients from a (noisy) dataset, in our case the floristic gradient developing along the southern mountain slope.
In this chapter we will try to model the first ordination axis, i.e., the floristic gradient, as a function of environmental predictors such as altitude, slope, catchment area and NDVI.
The corresponding model will allow us to make spatial predictions of the floristic composition anywhere in the study area.
To retrieve bias-reduced performance estimates, we will of course account for the likely presence of spatial autocorrelation with the help of spatial cross-validation (see chapter \@ref(spatial-cv)).

## Reducing dimensionality

Ordinations are a popular tool in vegetation science to extract the main information, frequently corresponding to ecological gradients, from large species-plot matrices mostly filled with 0s. 
However, they are also used in remote sensing (spectral bands + hyperspectral), the soil sciences, geomarketing, etc.
If you are unfamiliar with ordination techniques or in need of a refresher, have a look at Michael W. Palmers [webpage](http://ordination.okstate.edu/overview.htm) for a short introduction to popular ordination techniques in ecology and at @borcard_numerical_2011 for a deeper look how to apply these techniques in R. 
**vegan**'s package documentation is also very helpful (`vignette(package = "vegan")`).

Principal component analysis (PCA) is probably the most famous ordination technique. 
It is a great tool to reduce dimensionality if one can expect linear relationships between variables, and if the joint absence of a variable (for example calcium) in two plots (observations) can be considered a similarity.
This is barely the case with vegetation data.

For one, relationships are usually non-linear along environmental gradients.
That means the presence of a plant usually follows a unimodal relationship along a gradient (e.g., humidity, temperature or salinity) with a peak at the most favorable conditions and declining ends towards the unfavarable conditions. 

Secondly, the joint absence of a species in two plots is often hardly an indication for similarity.
Suppose a plant species is absent from the driest (e.g., an extreme desert) and the most moist locations (e.g., a tree savannah) of our sampling.
Then we really should refrain from counting this as a simlilarity because it is very likely that the only thing these two completely different environmental settings have in common in terms of floristic composition is the shared absence of species (except for rare ubiquist species). 

## Modeling

### Predictor assessment

We will use terrain attributes to model the floristic gradient extracted from the NDMS.
The terrain attributes can be computed from a digital elevation model using R-GIS bridges (see Chapter \@ref(gis)).
Specifically, we will compute catchment slope and catchment area.
Curvatures might also represent valuable predictors, in the exercise section you can find out if they would improve the modeling result.

To compute catchment area and catchment slope, we will make use of the `saga:sagawetnessindex` function.
^[Admittedly, it is a bit unsatisfying, that the only way of knowing that `sagawetnessindex` computes the desired terrain attributes, is to be familiar with SAGA and/or google for "SAGA catchment slope".]
`get_usage()` returns all function parameters and default values of a specific geoalgorithm.

```{r, eval=FALSE}
get_usage("saga:sagawetnessindex")
#>ALGORITHM: Saga wetness index
#>	DEM <ParameterRaster>
#>	SUCTION <ParameterNumber>
#>	AREA_TYPE <ParameterSelection>
#>	SLOPE_TYPE <ParameterSelection>
#>	SLOPE_MIN <ParameterNumber>
#>	SLOPE_OFF <ParameterNumber>
#>	SLOPE_WEIGHT <ParameterNumber>
#>	_RESAMPLING <ParameterSelection>
#>	AREA <OutputRaster>
#>	SLOPE <OutputRaster>
#>	AREA_MOD <OutputRaster>
#>	TWI <OutputRaster>
#>
#>AREA_TYPE(Type of Area)
#>	0 - [0] absolute catchment area
#>	1 - [1] square root of catchment area
#>	2 - [2] specific catchment area
#>SLOPE_TYPE(Type of Slope)
#>	0 - [0] local slope
#>	1 - [1] catchment slope
#>_RESAMPLING(Resampling method)
#>	0 - Nearest Neighbour
#>	1 - Bilinear Interpolation
#>	2 - Bicubic Spline Interpolation
#>	3 - B-Spline Interpolation
```

Subsequently, we can specify the needed parameters using R named arguments (see section \@ref(rqgis)).
Note that we can use a `RasterLayer` living in R's global environment to specify the input raster `DEM`.
Specifying 1 as the `SLOPE_TYPE` makes sure that the algorithm will return the catchment slope.
The resulting output rasters should be saved to a temporary folder.
Setting `load_output` to `TRUE` ensures that the resulting rasters will be imported into R.

```{r, eval=FALSE}
ta = run_qgis(alg = "saga:sagawetnessindex",
              DEM = dem,
              SLOPE_TYPE = 1, 
              SLOPE = file.path(tempdir(), "cslope.sdat"),
              AREA = file.path(tempdir(), "carea.sdat"),
              load_output = TRUE,
              show_output_paths = FALSE)
```

This gives back a list with two elements named `AREA` and `SLOPE`.
Let us convert the list into a raster stack and add two more rasters to it, namely `dem` containing the altitudinal values and `ndvi` representing the Normalized Difference Vegetation Index (NDVI).
The latter was computed using the red and near-infrared channel of a Landsat scene [@muenchow_predictive_2013;@muenchow_rqgis:_2017], and is available through the **RQGIS** package as a `RasterLayer`.

```{r}
data("ndvi", package = "RQGIS")
ta = c(dem, ndvi, ta) %>%
  stack
names(ta) = c("dem", "ndvi", "carea", "cslope")
```

Additionally, the curvature values are highly skewed to the right (`hist(ta$carea)`).
A log10-transformation makes the distribution more normal.

```{r, eval=FALSE}
ta$carea = log10(ta$carea)
```

```{r, eval=FALSE, echo=FALSE}
saveRDS(ta, "extdata/14-ta.rds")
```

Finally, we can extract the terrain attributes to our field observations.

```{r}
data("random_points", package = "RQGIS")
random_points[, names(ta)] = raster::extract(ta, random_points)
```


### Performance estimation

<!-- this should probably be only an exercise since everything has been covered in chapter spatial cv -->
The following code largely follows the steps we have introduced in section \@ref(svm).
The only differences are:

1. the response variable is numeric, hence a regression task will replace the classification task of section \@ref(svm).
1. instead of the AUROC which can only be used for categorical response variables, we will use the root mean squared error (RMSE) as performance measure.
1. we use a random forest model instead of a support vector machine which naturally goes along with different hyperparameters.

<!-- shortly introduce random forests --> 

### Spatial prediction

`r 50 * 5 * 5 * 100 + 500` models were necessary to retrieve bias-reduced performance estimates.
In the hyperparameter tuning fold, we found the best hyperparameter combination which in turn was used in the outer performance loop for predicting the test data of a specific spatial partition. 
This was done for five spatial partitions, and repeated a 100 times.
This yields in total 500 optimal hyperparameter combinations.
Which one should we use for making spatial predictions?
The answer is simple, none at all. 
Remember, the tuning was done to retrieve a bias-reduced performance estimate, not the best possible spatial prediction.
For this, one estimates the best hyperparameter combination on the complete dataset.
This mean, the inner hyperparameter tuning level is no longer needed which makes perfectly sense since we are applying our model to new data (unvisited field observations) for which the true outcomes are unavailable, hence testing is impossible. 
In short, we tune the hyperparameters for a good spatial prediction on the complete dataset via a 5-fold spatial CV with one repetition.
<!-- If we used more than one repetition (say 2) we would retrieve multiple optimal tuned hyperparameter combinations (say 2) -->

```{r}
# construct response-prediction matrix
d = data.frame(id = as.numeric(rownames(scores(rotnmds))),
               sc = scores(rotnmds)[, 1])
d = inner_join(random_points, d,  by = "id")

# extract coordinates
coords = sf::st_coordinates(d) %>% 
  as.data.frame %>%
  rename(x = X, y = Y)
# only keep variables needed for the modeling
d = dplyr::select(d, -id, -spri) %>%
  st_set_geometry(NULL)

# create task
task = makeRegrTask(data = d, target = "sc", coordinates = coords)

# learner
lrn = makeLearner(cl = "regr.ranger", predict.type = "response")
# spatial partitioning
rdesc = makeResampleDesc("SpCV", iters = 5)
# specifying the search space
ctrl = makeTuneControlRandom(maxit = 50L)
ps = makeParamSet(makeIntegerParam("mtry", lower = 1, upper = ncol(data)),
                  makeIntegerParam("num.trees", lower = 10, upper = 1000))
# hyperparamter tuning
res = tuneParams(lrn, task = task_sp,
                 resampling = rdesc,
                 par.set = ps, control = ctrl, 
                 measures = mlr::rmse)
```

This returns the best tuned hyperparameter per iteration (?) and then uses the best result from all iterations

```{r}
# create a learner using the optimal hyperparameters
lrn = makeLearner(cl = "classif.ranger",
                  predict.type = "prob",
                  mtry = res$x$mtry, num.trees = res$x$num.trees)
# build the model
mod_sp = train(learner = lrn, task = task_sp)
# ranger result which could be used with ranger.predict
getLearnerModel(mod_sp)  
```

## Ecological context

## Exercises
<!-- still, unrefined brain-storming -->
1. Compute catchment area and catchment slope using **RSAGA**.
1. Use profile and tangential curvature as additional predictors for the spatial prediction of the floristic gradient (hint: `grass7:r.slope.aspect`).
1. Retrieve the bias-reduced RMSE using spatial cross-validation including the estimation of optimal hyperparameter combinations in an inner tuning loop.
